---
title: Jointly Learning Consistent Causal Abstractions Over Multiple Interventional
  Distributions
section: Oral
openreview: RNs7aMS6zDq
abstract: An abstraction can be used to relate two structural causal models representing
  the same system at different levels of resolution. Learning abstractions which guarantee
  consistency with respect to interventional distributions would allow one to jointly
  reason about evidence across multiple levels of granularity while respecting the
  underlying cause-effect relationships. In this paper, we introduce a first framework
  for causal abstraction learning between SCMs based on the formalization of abstraction
  recently proposed by Rischel (2020). Based on that, we propose a differentiable
  programming solution that jointly solves a number of combinatorial sub-problems,
  and we study its performance and benefits against independent and sequential approaches
  on synthetic settings and on a challenging real-world problem related to electric
  vehicle battery manufacturing.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zennaro23a
month: 0
tex_title: Jointly Learning Consistent Causal Abstractions Over Multiple Interventional
  Distributions
firstpage: 88
lastpage: 121
page: 88-121
order: 88
cycles: false
bibtex_author: Zennaro, Fabio Massimo and Dr\'avucz, M\'at\'e and Apachitei, Geanina
  and Widanage, W. Dhammika and Damoulas, Theodoros
author:
- given: Fabio Massimo
  family: Zennaro
- given: Máté
  family: Drávucz
- given: Geanina
  family: Apachitei
- given: W. Dhammika
  family: Widanage
- given: Theodoros
  family: Damoulas
date: 2023-08-10
address:
container-title: Proceedings of the Second Conference on Causal Learning and Reasoning
volume: '213'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 8
  - 10
pdf: https://proceedings.mlr.press/v213/zennaro23a/zennaro23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
